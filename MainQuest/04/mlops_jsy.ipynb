{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 14:28:36.472555: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-12 14:28:36.475305: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-12 14:28:36.483348: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731389316.498013 2926522 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731389316.502114 2926522 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-12 14:28:36.515620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/configuration.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">859</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> FutureWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: section/key </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">core/sql_alchemy_conn</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\"> has been deprecated, you should use</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">database/sql_alchemy_conn</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\"> instead. Please update your `conf.get*` call to use the new name</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/\u001b[0m\u001b[1;33mconfiguration.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m859\u001b[0m\u001b[1;33m FutureWarning\u001b[0m\u001b[33m: section/key \u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mcore/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m has been deprecated, you should use\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mdatabase/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m instead. Please update your `conf.get*` call to use the new name\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "from datetime import datetime, timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.18.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjbw8715\u001b[0m (\u001b[33mjbw8715-chung-ang-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# Wandb 설정\n",
    "\n",
    "wandb.login()\n",
    "WANDB_PROJECT = \"text\"\n",
    "WANDB_ENTITY =\"ctan0722-innodigital\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # TensorFlow의 Keras API를 사용하여 MNIST 데이터셋 로드\n",
    "    #[[YOUR CODE]]\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # 데이터 정규화 (픽셀 값을 0과 1 사이로 변환)\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    \n",
    "    # 차원 추가 (CNN에 사용하기 위해 (28, 28) -> (28, 28, 1)로 변환)\n",
    "    x_train = x_train[..., tf.newaxis]\n",
    "    x_test = x_test[..., tf.newaxis]\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_model(learning_rate=0.001, conv1_filters=32, conv2_filters=64):\n",
    "    \"\"\"CNN 모델 생성\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # 첫 번째 합성곱 레이어\n",
    "        layers.Conv2D(conv1_filters, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # 두 번째 합성곱 레이어\n",
    "        layers.Conv2D(conv2_filters, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # 완전 연결층을 위한 플래튼 레이어\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # 완전 연결층\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')  # MNIST 데이터셋의 10개 클래스\n",
    "    ])\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "def train_model(**context):\n",
    "    \"\"\"모델 학습 및 W&B 로깅\"\"\"\n",
    "    # W&B 초기화\n",
    "    wandb.init(\n",
    "        project=\"mnist_classification\",  # 프로젝트 이름\n",
    "        config={\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"conv1_filters\": 32,\n",
    "            \"conv2_filters\": 64,\n",
    "            \"epochs\": 5,\n",
    "            \"batch_size\": 64\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 데이터 로드\n",
    "    (x_train, y_train), (x_test, y_test) = load_and_preprocess_data()\n",
    "    \n",
    "    # 모델 생성\n",
    "    config = wandb.config\n",
    "    model = create_model(\n",
    "        learning_rate=config.learning_rate,\n",
    "        conv1_filters=config.conv1_filters,\n",
    "        conv2_filters=config.conv2_filters\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=config.epochs,\n",
    "        batch_size=config.batch_size,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[wandb.keras.WandbCallback(save_graph=False, save_model=False)]\n",
    "    )\n",
    "    \n",
    "    # 모델 평가\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {test_accuracy}\")\n",
    "    \n",
    "    # W&B에 최종 메트릭 기록 (test_loss, test_accuracy)\n",
    "    wandb.log({\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy\n",
    "    })\n",
    "    \n",
    "    # 모델 저장\n",
    "    model.save(f\"mnist_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.keras\")\n",
    "    \n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_sweep():\n",
    "    \"\"\"W&B를 사용한 하이퍼파라미터 튜닝\"\"\"\n",
    "    sweep_config = {\n",
    "        'method': 'random',\n",
    "        'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n",
    "        'parameters': {\n",
    "            'learning_rate': {'values': [0.001, 0.01, 0.0001]},\n",
    "            'conv1_filters': {'values': [16, 32, 64]},\n",
    "            'conv2_filters': {'values': [32, 64, 128]},\n",
    "            'batch_size': {'values': [64, 128, 256]}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"text\")\n",
    "    wandb.agent(sweep_id, train_model, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aiffel04/my_project/wandb/run-20241112_143455-k45par45</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbw8715-chung-ang-university/mnist_classification/runs/k45par45' target=\"_blank\">gentle-night-1</a></strong> to <a href='https://wandb.ai/jbw8715-chung-ang-university/mnist_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbw8715-chung-ang-university/mnist_classification' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/mnist_classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbw8715-chung-ang-university/mnist_classification/runs/k45par45' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/mnist_classification/runs/k45par45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">107</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> UserWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Input(</span><span style=\"color: #808000; text-decoration-color: #808000\">shape</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">` object as the first layer in the model instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/\u001b[0m\u001b[1;33mbase_conv.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m107\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: Do not pass an `input_shape`\u001b[0m\u001b[33m/\u001b[0m\u001b[33m`input_dim` argument to a layer. When using Sequential models, prefer using an `\u001b[0m\u001b[1;33mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m` object as the first layer in the model instead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 14:34:56.981308: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - accuracy: 0.8639 - loss: 0.4473 - val_accuracy: 0.9838 - val_loss: 0.0558\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9817 - loss: 0.0593 - val_accuracy: 0.9886 - val_loss: 0.0372\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.9878 - loss: 0.0409 - val_accuracy: 0.9887 - val_loss: 0.0351\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0297 - val_accuracy: 0.9845 - val_loss: 0.0454\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9923 - loss: 0.0245 - val_accuracy: 0.9892 - val_loss: 0.0299\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0387\n",
      "Test accuracy: 0.9891999959945679\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇▇██</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▂▂▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▇▇▂█</td></tr><tr><td>val_loss</td><td>█▃▂▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9918</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>0.02993</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.02586</td></tr><tr><td>test_accuracy</td><td>0.9892</td></tr><tr><td>test_loss</td><td>0.02993</td></tr><tr><td>val_accuracy</td><td>0.9892</td></tr><tr><td>val_loss</td><td>0.02993</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gentle-night-1</strong> at: <a href='https://wandb.ai/jbw8715-chung-ang-university/mnist_classification/runs/k45par45' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/mnist_classification/runs/k45par45</a><br/> View project at: <a href='https://wandb.ai/jbw8715-chung-ang-university/mnist_classification' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/mnist_classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241112_143455-k45par45/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: sxu9u2ji\n",
      "Sweep URL: https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j6jjsh56 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aiffel04/my_project/wandb/run-20241112_143606-j6jjsh56</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/j6jjsh56' target=\"_blank\">lyric-sweep-1</a></strong> to <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/j6jjsh56' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/runs/j6jjsh56</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">107</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> UserWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Input(</span><span style=\"color: #808000; text-decoration-color: #808000\">shape</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">` object as the first layer in the model instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/\u001b[0m\u001b[1;33mbase_conv.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m107\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: Do not pass an `input_shape`\u001b[0m\u001b[33m/\u001b[0m\u001b[33m`input_dim` argument to a layer. When using Sequential models, prefer using an `\u001b[0m\u001b[1;33mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m` object as the first layer in the model instead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8212 - loss: 0.6340 - val_accuracy: 0.9712 - val_loss: 0.0908\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9752 - loss: 0.0824 - val_accuracy: 0.9790 - val_loss: 0.0606\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9820 - loss: 0.0571 - val_accuracy: 0.9816 - val_loss: 0.0529\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9870 - loss: 0.0440 - val_accuracy: 0.9874 - val_loss: 0.0366\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9875 - loss: 0.0376 - val_accuracy: 0.9885 - val_loss: 0.0350\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9841 - loss: 0.0443\n",
      "Test accuracy: 0.9884999990463257\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇▇██</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▂▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅██</td></tr><tr><td>val_loss</td><td>█▄▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98805</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>0.035</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.0377</td></tr><tr><td>test_accuracy</td><td>0.9885</td></tr><tr><td>test_loss</td><td>0.035</td></tr><tr><td>val_accuracy</td><td>0.9885</td></tr><tr><td>val_loss</td><td>0.035</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-1</strong> at: <a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/j6jjsh56' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/runs/j6jjsh56</a><br/> View project at: <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241112_143606-j6jjsh56/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p60icx9g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aiffel04/my_project/wandb/run-20241112_143653-p60icx9g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/p60icx9g' target=\"_blank\">hardy-sweep-2</a></strong> to <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/p60icx9g' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/runs/p60icx9g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">107</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> UserWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Input(</span><span style=\"color: #808000; text-decoration-color: #808000\">shape</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">` object as the first layer in the model instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/\u001b[0m\u001b[1;33mbase_conv.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m107\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: Do not pass an `input_shape`\u001b[0m\u001b[33m/\u001b[0m\u001b[33m`input_dim` argument to a layer. When using Sequential models, prefer using an `\u001b[0m\u001b[1;33mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m` object as the first layer in the model instead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 117ms/step - accuracy: 0.8340 - loss: 0.5869 - val_accuracy: 0.9814 - val_loss: 0.0574\n",
      "Epoch 2/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 116ms/step - accuracy: 0.9828 - loss: 0.0540 - val_accuracy: 0.9856 - val_loss: 0.0418\n",
      "Epoch 3/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - accuracy: 0.9879 - loss: 0.0380 - val_accuracy: 0.9863 - val_loss: 0.0419\n",
      "Epoch 4/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 115ms/step - accuracy: 0.9899 - loss: 0.0310 - val_accuracy: 0.9817 - val_loss: 0.0579\n",
      "Epoch 5/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 108ms/step - accuracy: 0.9897 - loss: 0.0299 - val_accuracy: 0.9883 - val_loss: 0.0393\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0502\n",
      "Test accuracy: 0.9883000254631042\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇███</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▂▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▁█</td></tr><tr><td>val_loss</td><td>█▂▂█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98987</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>0.03929</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.0304</td></tr><tr><td>test_accuracy</td><td>0.9883</td></tr><tr><td>test_loss</td><td>0.03929</td></tr><tr><td>val_accuracy</td><td>0.9883</td></tr><tr><td>val_loss</td><td>0.03929</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-sweep-2</strong> at: <a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/p60icx9g' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/runs/p60icx9g</a><br/> View project at: <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241112_143653-p60icx9g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: otlrawz6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aiffel04/my_project/wandb/run-20241112_143925-otlrawz6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/otlrawz6' target=\"_blank\">neat-sweep-3</a></strong> to <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/otlrawz6' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/runs/otlrawz6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">107</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> UserWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Input(</span><span style=\"color: #808000; text-decoration-color: #808000\">shape</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">` object as the first layer in the model instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/\u001b[0m\u001b[1;33mbase_conv.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m107\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: Do not pass an `input_shape`\u001b[0m\u001b[33m/\u001b[0m\u001b[33m`input_dim` argument to a layer. When using Sequential models, prefer using an `\u001b[0m\u001b[1;33mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m` object as the first layer in the model instead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - accuracy: 0.8465 - loss: 0.4679 - val_accuracy: 0.9761 - val_loss: 0.0739\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 47ms/step - accuracy: 0.9786 - loss: 0.0653 - val_accuracy: 0.9846 - val_loss: 0.0480\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 47ms/step - accuracy: 0.9841 - loss: 0.0506 - val_accuracy: 0.9809 - val_loss: 0.0590\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - accuracy: 0.9865 - loss: 0.0422 - val_accuracy: 0.9866 - val_loss: 0.0442\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9878 - loss: 0.0389 - val_accuracy: 0.9843 - val_loss: 0.0545\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0726\n",
      "Test accuracy: 0.9843000173568726\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇███</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▂▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▇▄█▆</td></tr><tr><td>val_loss</td><td>█▂▄▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98678</td></tr><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>0.04419</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.04267</td></tr><tr><td>test_accuracy</td><td>0.9843</td></tr><tr><td>test_loss</td><td>0.05454</td></tr><tr><td>val_accuracy</td><td>0.9843</td></tr><tr><td>val_loss</td><td>0.05454</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-sweep-3</strong> at: <a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/otlrawz6' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/runs/otlrawz6</a><br/> View project at: <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241112_143925-otlrawz6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sptiv28e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aiffel04/my_project/wandb/run-20241112_144130-sptiv28e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/sptiv28e' target=\"_blank\">lucky-sweep-4</a></strong> to <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/sptiv28e' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/runs/sptiv28e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">107</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> UserWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Input(</span><span style=\"color: #808000; text-decoration-color: #808000\">shape</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">` object as the first layer in the model instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/\u001b[0m\u001b[1;33mbase_conv.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m107\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: Do not pass an `input_shape`\u001b[0m\u001b[33m/\u001b[0m\u001b[33m`input_dim` argument to a layer. When using Sequential models, prefer using an `\u001b[0m\u001b[1;33mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m` object as the first layer in the model instead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.7993 - loss: 0.7172 - val_accuracy: 0.9749 - val_loss: 0.0834\n",
      "Epoch 2/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9724 - loss: 0.0884 - val_accuracy: 0.9833 - val_loss: 0.0530\n",
      "Epoch 3/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9812 - loss: 0.0594 - val_accuracy: 0.9865 - val_loss: 0.0453\n",
      "Epoch 4/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9863 - loss: 0.0457 - val_accuracy: 0.9871 - val_loss: 0.0412\n",
      "Epoch 5/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.9885 - loss: 0.0394 - val_accuracy: 0.9882 - val_loss: 0.0371\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9846 - loss: 0.0460\n",
      "Test accuracy: 0.9882000088691711\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇▇██</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▂▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁▅▇▇█</td></tr><tr><td>val_loss</td><td>█▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9884</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>0.03708</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.03856</td></tr><tr><td>test_accuracy</td><td>0.9882</td></tr><tr><td>test_loss</td><td>0.03708</td></tr><tr><td>val_accuracy</td><td>0.9882</td></tr><tr><td>val_loss</td><td>0.03708</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-sweep-4</strong> at: <a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/sptiv28e' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/runs/sptiv28e</a><br/> View project at: <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241112_144130-sptiv28e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eklpj49y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1_filters: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv2_filters: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aiffel04/my_project/wandb/run-20241112_144218-eklpj49y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/eklpj49y' target=\"_blank\">worldly-sweep-5</a></strong> to <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/sweeps/sxu9u2ji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/eklpj49y' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/runs/eklpj49y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">107</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> UserWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Input(</span><span style=\"color: #808000; text-decoration-color: #808000\">shape</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">` object as the first layer in the model instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/keras/src/layers/convolutional/\u001b[0m\u001b[1;33mbase_conv.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m107\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: Do not pass an `input_shape`\u001b[0m\u001b[33m/\u001b[0m\u001b[33m`input_dim` argument to a layer. When using Sequential models, prefer using an `\u001b[0m\u001b[1;33mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m` object as the first layer in the model instead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9069 - loss: 0.2862 - val_accuracy: 0.9794 - val_loss: 0.0649\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0585 - val_accuracy: 0.9793 - val_loss: 0.0696\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9863 - loss: 0.0473 - val_accuracy: 0.9839 - val_loss: 0.0560\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9873 - loss: 0.0414 - val_accuracy: 0.9789 - val_loss: 0.0807\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0405 - val_accuracy: 0.9805 - val_loss: 0.0767\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.0877\n",
      "Test accuracy: 0.9804999828338623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇███</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▂▂▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▂▂█▁▃</td></tr><tr><td>val_loss</td><td>▄▅▁█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98742</td></tr><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.05595</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.04307</td></tr><tr><td>test_accuracy</td><td>0.9805</td></tr><tr><td>test_loss</td><td>0.07668</td></tr><tr><td>val_accuracy</td><td>0.9805</td></tr><tr><td>val_loss</td><td>0.07668</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worldly-sweep-5</strong> at: <a href='https://wandb.ai/jbw8715-chung-ang-university/text/runs/eklpj49y' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text/runs/eklpj49y</a><br/> View project at: <a href='https://wandb.ai/jbw8715-chung-ang-university/text' target=\"_blank\">https://wandb.ai/jbw8715-chung-ang-university/text</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241112_144218-eklpj49y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Airflow DAG 정의\n",
    "\n",
    "import pendulum  # Airflow는 pendulum을 사용합니다\n",
    "\n",
    "local_tz = pendulum.timezone(\"Asia/Seoul\")  # 한국 시간대 사용\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'start_date': datetime(2024, 1, 1, tzinfo=local_tz),\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "dag = DAG(\n",
    "    'mnist_training_pipeline',\n",
    "    default_args=default_args,\n",
    "    description='MNIST 학습 파이프라인',\n",
    "    schedule = '@daily',\n",
    "    catchup=False\n",
    ")\n",
    "\n",
    "# DAG 태스크 정의\n",
    "preprocessing_task = PythonOperator(\n",
    "    task_id='load_and_preprocess_data',\n",
    "    python_callable=load_and_preprocess_data,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "training_task = PythonOperator(\n",
    "    task_id='train_model',\n",
    "    python_callable=train_model,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "hyperparameter_tuning_task = PythonOperator(\n",
    "    task_id='hyperparameter_tuning',\n",
    "    python_callable=hyperparameter_sweep,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "# 태스크 의존성 설정\n",
    "preprocessing_task >> training_task >> hyperparameter_tuning_task\n",
    "\n",
    "# Jupyter Notebook에서 직접 실행하기 위한 코드\n",
    "if __name__ == \"__main__\":\n",
    "    # 단일 실험 실행\n",
    "    train_model()\n",
    "\n",
    "    hyperparameter_sweep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/\u001b[0m\u001b[1;33mconfiguration.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m859\u001b[0m\u001b[1;33m FutureWarning\u001b[0m\u001b[33m: section/key \u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mcore/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m has been deprecated, you should use\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mdatabase/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m instead. Please update your `conf.get*` call to use the new name\u001b[0m\n",
      "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/cli/\u001b[0m\u001b[1;33mcli_config.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m49\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: `db upgrade` is deprecated. Use `db migrate` instead.\u001b[0m\n",
      "DB: sqlite:////home/aiffel04/airflow/airflow.db\n",
      "Performing upgrade to the metadata database sqlite:////home/aiffel04/airflow/airflow.db\n",
      "[\u001b[34m2024-11-12T14:43:13.979+0900\u001b[0m] {\u001b[34mmigration.py:\u001b[0m207} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n",
      "[\u001b[34m2024-11-12T14:43:13.980+0900\u001b[0m] {\u001b[34mmigration.py:\u001b[0m210} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n",
      "[\u001b[34m2024-11-12T14:43:13.981+0900\u001b[0m] {\u001b[34mmigration.py:\u001b[0m207} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n",
      "[\u001b[34m2024-11-12T14:43:13.981+0900\u001b[0m] {\u001b[34mmigration.py:\u001b[0m210} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n",
      "[\u001b[34m2024-11-12T14:43:13.982+0900\u001b[0m] {\u001b[34mdb.py:\u001b[0m1675} INFO\u001b[0m - Creating tables\u001b[0m\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "Database migrating done!\n"
     ]
    }
   ],
   "source": [
    "!airflow db upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/\u001b[0m\u001b[1;33mconfiguration.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m859\u001b[0m\u001b[1;33m FutureWarning\u001b[0m\u001b[33m: section/key \u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mcore/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m has been deprecated, you should use\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mdatabase/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m instead. Please update your `conf.get*` call to use the new name\u001b[0m\n",
      "DB: sqlite:////home/aiffel04/airflow/airflow.db\n",
      "This will drop existing tables if they exist. Proceed? (y/n)^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/bin/airflow\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/__main__.py\", line 62, in main\n",
      "    args.func(args)\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/cli/cli_config.py\", line 49, in command\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/providers_configuration_loader.py\", line 55, in wrapped_function\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/cli/commands/db_command.py\", line 64, in resetdb\n",
      "    if not (args.yes or input(\"This will drop existing tables if they exist. Proceed? (y/n)\").upper() == \"Y\"):\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/\u001b[0m\u001b[1;33mconfiguration.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m859\u001b[0m\u001b[1;33m FutureWarning\u001b[0m\u001b[33m: section/key \u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mcore/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m has been deprecated, you should use\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mdatabase/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m instead. Please update your `conf.get*` call to use the new name\u001b[0m\n",
      "\u001b[1;33m/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/\u001b[0m\u001b[1;33mproviders_configuration_loader.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m55\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: `db init` is deprecated.  Use `db migrate` instead to migrate the db and/or airflow connections create-default-connections to create the default connections\u001b[0m\n",
      "DB: sqlite:////home/aiffel04/airflow/airflow.db\n",
      "[\u001b[34m2024-11-12T11:30:45.412+0900\u001b[0m] {\u001b[34mmigration.py:\u001b[0m207} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:30:45.413+0900\u001b[0m] {\u001b[34mmigration.py:\u001b[0m210} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:30:45.513+0900\u001b[0m] {\u001b[34mmigration.py:\u001b[0m207} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:30:45.514+0900\u001b[0m] {\u001b[34mmigration.py:\u001b[0m210} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:30:45.514+0900\u001b[0m] {\u001b[34mmigration.py:\u001b[0m207} INFO\u001b[0m - Context impl \u001b[1mSQLiteImpl\u001b[22m.\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:30:45.515+0900\u001b[0m] {\u001b[34mmigration.py:\u001b[0m210} INFO\u001b[0m - Will assume \u001b[1mnon-transactional\u001b[22m DDL.\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:30:45.515+0900\u001b[0m] {\u001b[34mdb.py:\u001b[0m1675} INFO\u001b[0m - Creating tables\u001b[0m\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "WARNI [airflow.models.crypto] empty cryptography key - values will not be stored encrypted.\n",
      "Initialization done\n"
     ]
    }
   ],
   "source": [
    "!airflow db reset\n",
    "!airflow db init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminal에 서 실 행 함\n",
    "#airflow users create \\\n",
    "    #--username jungseoyeon \\\n",
    "    #--firstname 정 \\\n",
    "    #--lastname 서연 \\\n",
    "    #--role Admin \\\n",
    "    #--email jbw8715@naver.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-12T11:41:47.578+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m4435} INFO\u001b[0m - dagrun id: mnist_training_pipeline\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:47.588+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m4451} INFO\u001b[0m - created dagrun <DagRun mnist_training_pipeline @ 2024-11-10 00:00:00+09:00: manual__2024-11-10T00:00:00+09:00, state:running, queued_at: None. externally triggered: False>\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:47.608+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m4396} INFO\u001b[0m - [DAG TEST] starting task_id=load_and_preprocess_data map_index=-1\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:47.609+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m4399} INFO\u001b[0m - [DAG TEST] running task <TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [scheduled]>\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:47.623+0900\u001b[0m] {\u001b[34mworkday.py:\u001b[0m41} \u001b[33mWARNING\u001b[0m - \u001b[33mCould not import pandas. Holidays will not be considered.\u001b[0m\n",
      "[2024-11-12 11:41:47,678] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='mnist_training_pipeline' AIRFLOW_CTX_TASK_ID='load_and_preprocess_data' AIRFLOW_CTX_EXECUTION_DATE='2024-11-09T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-10T00:00:00+09:00'\n",
      "[\u001b[34m2024-11-12T11:41:47.678+0900\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m3132} INFO\u001b[0m - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='mnist_training_pipeline' AIRFLOW_CTX_TASK_ID='load_and_preprocess_data' AIRFLOW_CTX_EXECUTION_DATE='2024-11-09T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-10T00:00:00+09:00'\u001b[0m\n",
      "Task instance is in running state\n",
      " Previous state of the Task instance: queued\n",
      "Current task name:load_and_preprocess_data state:scheduled start_date:None\n",
      "Dag name:mnist_training_pipeline and current dag run status:running\n",
      "[\u001b[34m2024-11-12T11:41:47.684+0900\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m731} INFO\u001b[0m - ::endgroup::\u001b[0m\n",
      "[2024-11-12 11:41:47,968] {python.py:240} INFO - Done. Returned value was: ((array([[[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]], dtype=float32), array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)), (array([[[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]], dtype=float32), array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))\n",
      "[\u001b[34m2024-11-12T11:41:47.968+0900\u001b[0m] {\u001b[34mpython.py:\u001b[0m240} INFO\u001b[0m - Done. Returned value was: ((array([[[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]], dtype=float32), array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)), (array([[[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]], dtype=float32), array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:47.976+0900\u001b[0m] {\u001b[34mxcom.py:\u001b[0m690} \u001b[31mERROR\u001b[0m - \u001b[31mObject of type tuple is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your airflow config or make sure to decorate your object with attr.\u001b[0m\n",
      "[2024-11-12 11:41:47,976] {taskinstance.py:3311} ERROR - Task failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 92, in default\n",
      "    return serialize(o)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 190, in serialize\n",
      "    raise TypeError(f\"cannot serialize object of type {cls}\")\n",
      "TypeError: cannot serialize object of type <class 'numpy.ndarray'>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 789, in _execute_task\n",
      "    task_instance.xcom_push(key=XCOM_RETURN_KEY, value=xcom_value, session=session_or_null)\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3639, in xcom_push\n",
      "    XCom.set(\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py\", line 166, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 249, in set\n",
      "    value = cls.serialize_value(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 688, in serialize_value\n",
      "    return json.dumps(value, cls=XComEncoder).encode(\"UTF-8\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 103, in encode\n",
      "    o = self.default(o)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 94, in default\n",
      "    return super().default(o)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type tuple is not JSON serializable\n",
      "[\u001b[34m2024-11-12T11:41:47.976+0900\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m3311} \u001b[31mERROR\u001b[0m - \u001b[31mTask failed with exception\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 92, in default\n",
      "    return serialize(o)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 190, in serialize\n",
      "    raise TypeError(f\"cannot serialize object of type {cls}\")\n",
      "TypeError: cannot serialize object of type <class 'numpy.ndarray'>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 789, in _execute_task\n",
      "    task_instance.xcom_push(key=XCOM_RETURN_KEY, value=xcom_value, session=session_or_null)\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3639, in xcom_push\n",
      "    XCom.set(\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py\", line 166, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 249, in set\n",
      "    value = cls.serialize_value(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 688, in serialize_value\n",
      "    return json.dumps(value, cls=XComEncoder).encode(\"UTF-8\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 103, in encode\n",
      "    o = self.default(o)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 94, in default\n",
      "    return super().default(o)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type tuple is not JSON serializable\n",
      "Task instance in failure state\n",
      "Task start:None end:2024-11-12 02:41:47.983083+00:00 duration:None\n",
      "Task:<Task(PythonOperator): load_and_preprocess_data> dag:<DAG: mnist_training_pipeline> dagrun:<DagRun mnist_training_pipeline @ 2024-11-09 15:00:00+00:00: manual__2024-11-10T00:00:00+09:00, state:running, queued_at: None. externally triggered: False>\n",
      "Failure caused by Object of type tuple is not JSON serializable\n",
      "[\u001b[34m2024-11-12T11:41:47.983+0900\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1225} INFO\u001b[0m - Marking task as UP_FOR_RETRY. dag_id=mnist_training_pipeline, task_id=load_and_preprocess_data, run_id=manual__2024-11-10T00:00:00+09:00, execution_date=20241109T150000, start_date=, end_date=20241112T024147\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:47.990+0900\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m340} INFO\u001b[0m - ::group::Post task execution logs\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:47.990+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3090} \u001b[31mERROR\u001b[0m - \u001b[31mTask failed; ti=<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 92, in default\n",
      "    return serialize(o)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 190, in serialize\n",
      "    raise TypeError(f\"cannot serialize object of type {cls}\")\n",
      "TypeError: cannot serialize object of type <class 'numpy.ndarray'>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/dag.py\", line 3083, in test\n",
      "    _run_task(\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/dag.py\", line 4400, in _run_task\n",
      "    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3005, in _run_raw_task\n",
      "    return _run_raw_task(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 273, in _run_raw_task\n",
      "    TaskInstance._execute_task_with_callbacks(\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3159, in _execute_task_with_callbacks\n",
      "    result = self._execute_task(context, task_orig)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3183, in _execute_task\n",
      "    return _execute_task(self, context, task_orig)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 789, in _execute_task\n",
      "    task_instance.xcom_push(key=XCOM_RETURN_KEY, value=xcom_value, session=session_or_null)\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3639, in xcom_push\n",
      "    XCom.set(\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py\", line 166, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 249, in set\n",
      "    value = cls.serialize_value(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 688, in serialize_value\n",
      "    return json.dumps(value, cls=XComEncoder).encode(\"UTF-8\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 103, in encode\n",
      "    o = self.default(o)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 94, in default\n",
      "    return super().default(o)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type tuple is not JSON serializable\n",
      "[\u001b[34m2024-11-12T11:41:48.001+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:49.016+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:50.033+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:51.041+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:52.050+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:53.059+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:54.069+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:55.079+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:56.089+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:57.100+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:58.109+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:41:59.119+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:00.129+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:01.142+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:02.150+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:03.158+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:04.168+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:05.181+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:06.190+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:07.199+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:08.208+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:09.216+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:10.225+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:11.234+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:12.242+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:13.249+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:14.257+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:15.266+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:16.275+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:17.285+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:18.292+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:19.300+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:20.309+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:21.316+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:22.323+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:23.333+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:24.342+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:25.352+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:26.360+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:27.370+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:28.387+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:29.395+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:30.402+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:31.410+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:32.419+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:33.427+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:34.435+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:35.443+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:36.452+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:37.460+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:38.471+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:39.480+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:40.489+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:41.498+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:42.505+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:43.516+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:44.524+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:45.532+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:46.539+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:47.547+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:48.556+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:49.567+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:50.577+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:51.586+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:52.598+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:53.607+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:54.616+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:55.625+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:56.635+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:57.647+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:58.657+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:42:59.665+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:00.672+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:01.680+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:02.690+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:03.700+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:04.709+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:05.717+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:06.725+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:07.735+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:08.742+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:09.752+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:10.759+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:11.767+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:12.774+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:13.782+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:14.791+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:15.798+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:16.806+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:17.815+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:18.824+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:19.832+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:20.839+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:21.847+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:22.855+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:23.865+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:24.873+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:25.883+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:26.893+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:27.902+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:28.909+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:29.917+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:30.924+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:31.933+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:32.939+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:33.949+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:34.957+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:35.968+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:36.976+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:37.987+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:38.994+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:40.002+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:41.012+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:42.019+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:43.029+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:44.039+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:45.046+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:46.053+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:47.062+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:48.071+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:49.079+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:50.087+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:51.095+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:52.103+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:53.111+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:54.119+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:55.128+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:56.139+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:57.147+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:58.155+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:43:59.163+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:00.172+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:01.184+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:02.194+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:03.203+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:04.214+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:05.227+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:06.238+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:07.246+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:08.256+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:09.264+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:10.274+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:11.284+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:12.295+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:13.304+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:14.317+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:15.329+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:16.338+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:17.346+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:18.354+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:19.361+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:20.371+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:21.379+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:22.386+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:23.394+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:24.402+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:25.411+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:26.420+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:27.428+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:28.436+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:29.443+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:30.452+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:31.461+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:32.470+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:33.480+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:34.489+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:35.499+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:36.508+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:37.518+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:38.525+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:39.533+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:40.541+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:41.550+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:42.558+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:43.567+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:44.578+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:45.585+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:46.595+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:47.602+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:48.610+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:49.619+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:50.628+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:51.636+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:52.643+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:53.652+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:54.660+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:55.669+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:56.680+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:57.688+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:58.697+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:44:59.707+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:00.715+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:01.722+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:02.732+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:03.741+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:04.751+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:05.759+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:06.769+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:07.777+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:08.786+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:09.793+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:10.802+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:11.813+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:12.821+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:13.832+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:14.839+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:15.851+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:16.859+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:17.867+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:18.876+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:19.884+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:20.891+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:21.900+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:22.907+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:23.916+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:24.924+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:25.932+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:26.940+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:27.947+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:28.959+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:29.969+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:30.976+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:31.985+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:32.995+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:34.004+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:35.011+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:36.021+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:37.029+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:38.039+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:39.052+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:40.059+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:41.068+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:42.077+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:43.085+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:44.092+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:45.102+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:46.110+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:47.121+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:48.131+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:49.141+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:50.151+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:51.160+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:52.168+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:53.176+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:54.184+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:55.192+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:56.200+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:57.208+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:58.216+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:45:59.225+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:00.233+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:01.242+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:02.249+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:03.260+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:04.268+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:05.276+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:06.284+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:07.292+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:08.303+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:09.310+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:10.320+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:11.327+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:12.335+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:13.343+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:14.351+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:15.360+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:16.369+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:17.379+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:18.387+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:19.398+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:20.405+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:21.413+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:22.422+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:23.437+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:24.448+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:25.456+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:26.467+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:27.474+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:28.485+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:29.493+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:30.500+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:31.508+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:32.518+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:33.527+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:34.536+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:35.544+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:36.553+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:37.563+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:38.573+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:39.582+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:40.590+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:41.601+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:42.612+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:43.620+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:44.628+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:45.637+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:46.646+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:47.655+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [up_for_retry]>, <TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>, <TaskInstance: mnist_training_pipeline.train_model manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:48.664+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m4396} INFO\u001b[0m - [DAG TEST] starting task_id=load_and_preprocess_data map_index=-1\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:48.664+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m4399} INFO\u001b[0m - [DAG TEST] running task <TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [scheduled]>\u001b[0m\n",
      "[2024-11-12 11:46:48,680] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='mnist_training_pipeline' AIRFLOW_CTX_TASK_ID='load_and_preprocess_data' AIRFLOW_CTX_EXECUTION_DATE='2024-11-09T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-10T00:00:00+09:00'\n",
      "[\u001b[34m2024-11-12T11:46:48.680+0900\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m3132} INFO\u001b[0m - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='mnist_training_pipeline' AIRFLOW_CTX_TASK_ID='load_and_preprocess_data' AIRFLOW_CTX_EXECUTION_DATE='2024-11-09T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-10T00:00:00+09:00'\u001b[0m\n",
      "Task instance is in running state\n",
      " Previous state of the Task instance: queued\n",
      "Current task name:load_and_preprocess_data state:scheduled start_date:None\n",
      "Dag name:mnist_training_pipeline and current dag run status:running\n",
      "[\u001b[34m2024-11-12T11:46:48.681+0900\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m731} INFO\u001b[0m - ::endgroup::\u001b[0m\n",
      "[2024-11-12 11:46:48,971] {python.py:240} INFO - Done. Returned value was: ((array([[[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]], dtype=float32), array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)), (array([[[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]], dtype=float32), array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))\n",
      "[\u001b[34m2024-11-12T11:46:48.971+0900\u001b[0m] {\u001b[34mpython.py:\u001b[0m240} INFO\u001b[0m - Done. Returned value was: ((array([[[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]], dtype=float32), array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)), (array([[[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]],\n",
      "\n",
      "\n",
      "       [[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]]], dtype=float32), array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:48.981+0900\u001b[0m] {\u001b[34mxcom.py:\u001b[0m690} \u001b[31mERROR\u001b[0m - \u001b[31mObject of type tuple is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your airflow config or make sure to decorate your object with attr.\u001b[0m\n",
      "[2024-11-12 11:46:48,982] {taskinstance.py:3311} ERROR - Task failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 92, in default\n",
      "    return serialize(o)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 190, in serialize\n",
      "    raise TypeError(f\"cannot serialize object of type {cls}\")\n",
      "TypeError: cannot serialize object of type <class 'numpy.ndarray'>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 789, in _execute_task\n",
      "    task_instance.xcom_push(key=XCOM_RETURN_KEY, value=xcom_value, session=session_or_null)\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3639, in xcom_push\n",
      "    XCom.set(\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py\", line 166, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 249, in set\n",
      "    value = cls.serialize_value(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 688, in serialize_value\n",
      "    return json.dumps(value, cls=XComEncoder).encode(\"UTF-8\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 103, in encode\n",
      "    o = self.default(o)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 94, in default\n",
      "    return super().default(o)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type tuple is not JSON serializable\n",
      "[\u001b[34m2024-11-12T11:46:48.982+0900\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m3311} \u001b[31mERROR\u001b[0m - \u001b[31mTask failed with exception\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 92, in default\n",
      "    return serialize(o)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 190, in serialize\n",
      "    raise TypeError(f\"cannot serialize object of type {cls}\")\n",
      "TypeError: cannot serialize object of type <class 'numpy.ndarray'>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 789, in _execute_task\n",
      "    task_instance.xcom_push(key=XCOM_RETURN_KEY, value=xcom_value, session=session_or_null)\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3639, in xcom_push\n",
      "    XCom.set(\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py\", line 166, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 249, in set\n",
      "    value = cls.serialize_value(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 688, in serialize_value\n",
      "    return json.dumps(value, cls=XComEncoder).encode(\"UTF-8\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 103, in encode\n",
      "    o = self.default(o)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 94, in default\n",
      "    return super().default(o)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type tuple is not JSON serializable\n",
      "Task instance in failure state\n",
      "Task start:None end:2024-11-12 02:46:48.988179+00:00 duration:None\n",
      "Task:<Task(PythonOperator): load_and_preprocess_data> dag:<DAG: mnist_training_pipeline> dagrun:<DagRun mnist_training_pipeline @ 2024-11-09 15:00:00+00:00: manual__2024-11-10T00:00:00+09:00, state:running, queued_at: None. externally triggered: False>\n",
      "Failure caused by Object of type tuple is not JSON serializable\n",
      "[\u001b[34m2024-11-12T11:46:48.988+0900\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1225} INFO\u001b[0m - Marking task as FAILED. dag_id=mnist_training_pipeline, task_id=load_and_preprocess_data, run_id=manual__2024-11-10T00:00:00+09:00, execution_date=20241109T150000, start_date=, end_date=20241112T024648\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:48.994+0900\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m340} INFO\u001b[0m - ::group::Post task execution logs\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:48.995+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3090} \u001b[31mERROR\u001b[0m - \u001b[31mTask failed; ti=<TaskInstance: mnist_training_pipeline.load_and_preprocess_data manual__2024-11-10T00:00:00+09:00 [failed]>\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 92, in default\n",
      "    return serialize(o)\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 151, in serialize\n",
      "    return encode(classname or serialized_classname, version, serialize(data, depth + 1))\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 128, in serialize\n",
      "    return [serialize(d, depth + 1) for d in o]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/serialization/serde.py\", line 190, in serialize\n",
      "    raise TypeError(f\"cannot serialize object of type {cls}\")\n",
      "TypeError: cannot serialize object of type <class 'numpy.ndarray'>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/dag.py\", line 3083, in test\n",
      "    _run_task(\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/dag.py\", line 4400, in _run_task\n",
      "    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3005, in _run_raw_task\n",
      "    return _run_raw_task(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 273, in _run_raw_task\n",
      "    TaskInstance._execute_task_with_callbacks(\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3159, in _execute_task_with_callbacks\n",
      "    result = self._execute_task(context, task_orig)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3183, in _execute_task\n",
      "    return _execute_task(self, context, task_orig)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 789, in _execute_task\n",
      "    task_instance.xcom_push(key=XCOM_RETURN_KEY, value=xcom_value, session=session_or_null)\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/taskinstance.py\", line 3639, in xcom_push\n",
      "    XCom.set(\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py\", line 166, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/session.py\", line 94, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 249, in set\n",
      "    value = cls.serialize_value(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/models/xcom.py\", line 688, in serialize_value\n",
      "    return json.dumps(value, cls=XComEncoder).encode(\"UTF-8\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 103, in encode\n",
      "    o = self.default(o)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/my_project/aiffel/lib/python3.12/site-packages/airflow/utils/json.py\", line 94, in default\n",
      "    return super().default(o)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/aiffel04/anaconda3/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type tuple is not JSON serializable\n",
      "[\u001b[34m2024-11-12T11:46:49.007+0900\u001b[0m] {\u001b[34mdag.py:\u001b[0m3061} \u001b[33mWARNING\u001b[0m - \u001b[33mNo tasks to run. unrunnable tasks: {<TaskInstance: mnist_training_pipeline.hyperparameter_tuning manual__2024-11-10T00:00:00+09:00 [None]>}\u001b[0m\n",
      "[\u001b[34m2024-11-12T11:46:50.019+0900\u001b[0m] {\u001b[34mdagrun.py:\u001b[0m823} \u001b[31mERROR\u001b[0m - \u001b[31mMarking run <DagRun mnist_training_pipeline @ 2024-11-09 15:00:00+00:00: manual__2024-11-10T00:00:00+09:00, state:running, queued_at: None. externally triggered: False> failed\u001b[0m\n",
      "Dag run  in failure state\n",
      "Dag information:mnist_training_pipeline Run id: manual__2024-11-10T00:00:00+09:00 external trigger: False\n",
      "Failed with message: task_failure\n",
      "[\u001b[34m2024-11-12T11:46:50.020+0900\u001b[0m] {\u001b[34mdagrun.py:\u001b[0m905} INFO\u001b[0m - DagRun Finished: dag_id=mnist_training_pipeline, execution_date=2024-11-09 15:00:00+00:00, run_id=manual__2024-11-10T00:00:00+09:00, run_start_date=2024-11-09 15:00:00+00:00, run_end_date=2024-11-12 02:46:50.020255+00:00, run_duration=215210.020255, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-11-08 15:00:00+00:00, data_interval_end=2024-11-09 15:00:00+00:00, dag_hash=None\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DagRun mnist_training_pipeline @ 2024-11-09 15:00:00+00:00: manual__2024-11-10T00:00:00+09:00, state:failed, queued_at: None. externally triggered: False>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution_date = datetime(2024, 11, 10, tzinfo=local_tz)\n",
    "dag.test(execution_date=execution_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/tmp/ipykernel_270309/1951795695.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">109</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> RemovedInAirflow3Warning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/tmp/ipykernel_270309/\u001b[0m\u001b[1;33m1951795695.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m109\u001b[0m\u001b[1;33m RemovedInAirflow3Warning\u001b[0m\u001b[33m: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nefgi2hx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-sweep-5</strong> at: <a href='https://wandb.ai/ctan0722-innodigital/text/runs/nefgi2hx' target=\"_blank\">https://wandb.ai/ctan0722-innodigital/text/runs/nefgi2hx</a><br/> View project at: <a href='https://wandb.ai/ctan0722-innodigital/text' target=\"_blank\">https://wandb.ai/ctan0722-innodigital/text</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241112_120014-nefgi2hx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nefgi2hx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aiffel04/my_project/wandb/run-20241112_120132-nefgi2hx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ctan0722-innodigital/text/runs/nefgi2hx' target=\"_blank\">lemon-sweep-5</a></strong> to <a href='https://wandb.ai/ctan0722-innodigital/text' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ctan0722-innodigital/text/sweeps/fpajsfp9' target=\"_blank\">https://wandb.ai/ctan0722-innodigital/text/sweeps/fpajsfp9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ctan0722-innodigital/text' target=\"_blank\">https://wandb.ai/ctan0722-innodigital/text</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ctan0722-innodigital/text/sweeps/fpajsfp9' target=\"_blank\">https://wandb.ai/ctan0722-innodigital/text/sweeps/fpajsfp9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ctan0722-innodigital/text/runs/nefgi2hx' target=\"_blank\">https://wandb.ai/ctan0722-innodigital/text/runs/nefgi2hx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # MNIST 데이터셋 로드 및 전처리\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    x_train = x_train[..., np.newaxis]\n",
    "    x_test = x_test[..., np.newaxis]\n",
    "    \n",
    "    # JSON 직렬화를 위해 리스트로 변환\n",
    "    return {\n",
    "        \"x_train\": x_train.tolist(),\n",
    "        \"y_train\": y_train.tolist(),\n",
    "        \"x_test\": x_test.tolist(),\n",
    "        \"y_test\": y_test.tolist()\n",
    "    }\n",
    "\n",
    "def train_model(**kwargs):\n",
    "    \"\"\"모델 학습 및 W&B 로깅\"\"\"\n",
    "    \n",
    "    # W&B 초기화\n",
    "    wandb.init(\n",
    "        project=\"mnist_classification\",\n",
    "        config={\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"conv1_filters\": 32,\n",
    "            \"conv2_filters\": 64,\n",
    "            \"epochs\": 5,\n",
    "            \"batch_size\": 64\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 데이터 로드: Airflow 실행 시 XCom에서 데이터 가져오기\n",
    "    if 'ti' in kwargs:\n",
    "        data = kwargs['ti'].xcom_pull(task_ids='load_and_preprocess_data')\n",
    "        x_train = np.array(data['x_train'])\n",
    "        y_train = np.array(data['y_train'])\n",
    "        x_test = np.array(data['x_test'])\n",
    "        y_test = np.array(data['y_test'])\n",
    "    else:\n",
    "        # Jupyter Notebook에서 실행될 때는 데이터를 직접 로드\n",
    "        data = load_and_preprocess_data()\n",
    "        x_train = np.array(data['x_train'])\n",
    "        y_train = np.array(data['y_train'])\n",
    "        x_test = np.array(data['x_test'])\n",
    "        y_test = np.array(data['y_test'])\n",
    "    \n",
    "    # 모델 생성\n",
    "    config = wandb.config\n",
    "    model = create_model(\n",
    "        learning_rate=config.learning_rate,\n",
    "        conv1_filters=config.conv1_filters,\n",
    "        conv2_filters=config.conv2_filters\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=config.epochs,\n",
    "        batch_size=config.batch_size,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[wandb.keras.WandbCallback(save_graph=False, save_model=False)]\n",
    "    )\n",
    "\n",
    "    # 모델 평가\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {test_accuracy}\")\n",
    "    \n",
    "    # W&B에 최종 메트릭 기록\n",
    "    wandb.log({\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy\n",
    "    })\n",
    "    \n",
    "    # 모델 저장\n",
    "    model.save(f\"mnist_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.keras\")\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 튜닝 함수\n",
    "def hyperparameter_sweep():\n",
    "    sweep_config = {\n",
    "        'method': 'random',\n",
    "        'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n",
    "        'parameters': {\n",
    "            'learning_rate': {'values': [0.001, 0.01, 0.0001]},\n",
    "            'conv1_filters': {'values': [16, 32, 64]},\n",
    "            'conv2_filters': {'values': [32, 64, 128]},\n",
    "            'batch_size': {'values': [64, 128, 256]}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"mnist_classification\")\n",
    "    wandb.agent(sweep_id, train_model, count=5)\n",
    "\n",
    "# Airflow DAG 정의\n",
    "local_tz = pendulum.timezone(\"Asia/Seoul\")\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'start_date': datetime(2024, 1, 1, tzinfo=local_tz),\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'mnist_training_pipeline',\n",
    "    default_args=default_args,\n",
    "    description='MNIST 학습 파이프라인',\n",
    "    schedule_interval='@daily',\n",
    "    catchup=False\n",
    ")\n",
    "\n",
    "# DAG 태스크 정의\n",
    "preprocessing_task = PythonOperator(\n",
    "    task_id='load_and_preprocess_data',\n",
    "    python_callable=load_and_preprocess_data,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "training_task = PythonOperator(\n",
    "    task_id='train_model',\n",
    "    python_callable=train_model,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "hyperparameter_tuning_task = PythonOperator(\n",
    "    task_id='hyperparameter_tuning',\n",
    "    python_callable=hyperparameter_sweep,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "# 태스크 의존성 설정\n",
    "preprocessing_task >> training_task >> hyperparameter_tuning_task\n",
    "\n",
    "# Jupyter Notebook에서 직접 실행하기 위한 코드\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()\n",
    "    hyperparameter_sweep()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
